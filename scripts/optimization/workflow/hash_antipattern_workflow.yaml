# 
#  Copyright 2023 Google LLC
# 
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
# 
#      http://www.apache.org/licenses/LICENSE-2.0
# 
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

main:
    params: [args]
    steps:
    - assign_vars:
        assign:
        - queryHash: "DECLARE num_days_to_scan INT64 DEFAULT 30;"
        - queryHash: ${queryHash+" "+ "CREATE TEMP FUNCTION num_stages_with_perf_insights(query_info ANY TYPE) AS ("}
        - queryHash: ${queryHash+" "+ "COALESCE(("}
        - queryHash: ${queryHash+" "+ "SELECT SUM(IF(i.slot_contention, 1, 0) + IF(i.insufficient_shuffle_quota, 1, 0))"}
        - queryHash: ${queryHash+" "+ "FROM UNNEST(query_info.performance_insights.stage_performance_standalone_insights) i), 0)"}
        - queryHash: ${queryHash+" "+ "+ COALESCE(ARRAY_LENGTH(query_info.performance_insights.stage_performance_change_insights), 0)"}
        - queryHash: ${queryHash+" "+ ");"}
        - queryHash: ${queryHash+" "+ "CREATE SCHEMA IF NOT EXISTS optimization_workshop;"}
        - queryHash: ${queryHash+" "+ "CREATE OR REPLACE TABLE optimization_workshop.queries_grouped_by_hash AS"}
        - queryHash: ${queryHash+" "+ "SELECT"}
        - queryHash: ${queryHash+" "+ "statement_type,"}
        - queryHash: ${queryHash+" "+ "query_info.query_hashes.normalized_literals                              AS id,"}
        - queryHash: ${queryHash+" "+ "COUNT(DISTINCT DATE(start_time))                                         AS days_active,"}
        - queryHash: ${queryHash+" "+ "ARRAY_AGG(DISTINCT project_id IGNORE NULLS)                              AS project_ids,"}
        - queryHash: ${queryHash+" "+ "ARRAY_AGG(DISTINCT reservation_id IGNORE NULLS)                          AS reservation_ids,"}
        - queryHash: ${queryHash+" "+ "SUM(num_stages_with_perf_insights(query_info))                           AS num_stages_with_perf_insights,"}
        - queryHash: ${queryHash+" "+ "COUNT(DISTINCT (project_id || ':us.' || job_id))                         AS job_count,"}
        - queryHash: ${queryHash+" "+ "ARRAY_AGG("}
        - queryHash: ${queryHash+" "+ "STRUCT("}
        - queryHash: ${queryHash+" "+ "bqutil.fn.job_url(project_id || ':us.' || parent_job_id) AS parent_job_url,"}
        - queryHash: ${queryHash+" "+ "bqutil.fn.job_url(project_id || ':us.' || job_id) AS job_url,"}
        - queryHash: ${queryHash+" "+ "parent_job_id, query as query_text"}
        - queryHash: ${queryHash+" "+ ")"}
        - queryHash: ${queryHash+" "+ "ORDER BY total_slot_ms"}
        - queryHash: ${queryHash+" "+ "DESC LIMIT 10)                                                         AS top_10_jobs,"}
        - queryHash: ${queryHash+" "+ "ARRAY_AGG(DISTINCT user_email)                                           AS user_emails,"}
        - queryHash: ${queryHash+" "+ "SUM(total_bytes_processed) / POW(1024, 3)                                AS total_gigabytes_processed,"}
        - queryHash: ${queryHash+" "+ "AVG(total_bytes_processed) / POW(1024, 3)                                AS avg_gigabytes_processed,"}
        - queryHash: ${queryHash+" "+ "SUM(total_slot_ms) / (1000 * 60 * 60)                                    AS total_slot_hours,"}
        - queryHash: ${queryHash+" "+ "AVG(total_slot_ms) / (1000 * 60 * 60)                                    AS avg_total_slot_hours_per_active_day,"}
        - queryHash: ${queryHash+" "+ "AVG(TIMESTAMP_DIFF(end_time, start_time, SECOND) )                       AS avg_job_duration_seconds,"}
        - queryHash: ${queryHash+" "+ "ARRAY_AGG(DISTINCT FORMAT('%T',labels))                                  AS labels,"}
        - queryHash: ${queryHash+" "+ "SUM(total_slot_ms / TIMESTAMP_DIFF(end_time, start_time, MILLISECOND))   AS total_slots,"}
        - queryHash: ${queryHash+" "+ "AVG(total_slot_ms / TIMESTAMP_DIFF(end_time, start_time, MILLISECOND))   AS avg_total_slots,"}
        - queryHash: ${queryHash+" "+ "ANY_VALUE(ARRAY("}
        - queryHash: ${queryHash+" "+ "SELECT"}
        - queryHash: ${queryHash+" "+ "ref_table.project_id || '.' ||"}
        - queryHash: ${queryHash+" "+ "IF(STARTS_WITH(ref_table.dataset_id, '_'), 'TEMP', ref_table.dataset_id)"}
        - queryHash: ${queryHash+" "+ "|| '.' || ref_table.table_id"}
        - queryHash: ${queryHash+" "+ "FROM UNNEST(referenced_tables) ref_table"}
        - queryHash: ${queryHash+" "+ "))                                                                       AS referenced_tables,"}
        - queryHash: ${queryHash+" "+ "FROM `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT"}
        - queryHash: ${queryHash+" "+ "WHERE"}
        - queryHash: ${queryHash+" "+ "DATE(creation_time) >= CURRENT_DATE - num_days_to_scan"}
        - queryHash: ${queryHash+" "+ "AND state = 'DONE'"}
        - queryHash: ${queryHash+" "+ "AND error_result IS NULL"}
        - queryHash: ${queryHash+" "+ "AND job_type = 'QUERY'"}
        - queryHash: ${queryHash+" "+ "AND statement_type != 'SCRIPT' GROUP BY statement_type, id;"}
        - queryHash: ${queryHash+" "+ "alter table `optimization_workshop.queries_grouped_by_hash` add column query string, add column job_id string;"}
        - queryHash: ${queryHash+" "+ "update `optimization_workshop.queries_grouped_by_hash` set query = top_10_jobs[OFFSET(0)].query_text, job_id = top_10_jobs[OFFSET(0)].parent_job_id WHERE true;"}
    - runQueriesGroupedByHash:
        call: googleapis.bigquery.v2.jobs.query
        args:
            projectId: ${args.project}
            body:
                useLegacySql: false
                query: ${queryHash}
    - runAntiPatternJob:
        call: googleapis.run.v1.namespaces.jobs.run
        args:
            name: ${"namespaces/" + args.project +  "/jobs/bigquery-antipattern-recognition"}
            location: "us-central1"
    - runJoinAntiPattern:
        call: googleapis.bigquery.v2.jobs.query
        args:
            projectId: ${args.project}
            body:
                useLegacySql: false
                query: "CREATE OR REPLACE TABLE optimization_workshop.queries_grouped_by_hash AS (select r.*, o.recommendation from optimization_workshop.queries_grouped_by_hash as r full outer join optimization_workshop.antipattern_output_table as o ON r.id = o.job_id)"
    - runCreateTopJobs:
            call: googleapis.bigquery.v2.jobs.query
            args:
                projectId: ${args.project}
                body:
                    useLegacySql: false
                    query: "CREATE OR REPLACE TABLE optimization_workshop.top_hash_jobs AS (select id as hash_id, job_id, query, recommendation from optimization_workshop.queries_grouped_by_hash order by total_slots desc limit 5 )"
    - runCreateTopJobsInfoSchema:
        call: googleapis.bigquery.v2.jobs.query
        args:
            projectId: ${args.project}
            body:
                useLegacySql: false
                query: "CREATE OR REPLACE TABLE optimization_workshop.top_hash_jobs AS (SELECT j.*, t.recommendation  from  optimization_workshop.top_hash_jobs as t JOIN `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT as j ON t.job_id = j.job_id)"
                    